{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Exercises\n\nThere are three exercises in this notebook:\n\n1. Use the cross-validation method to test the linear regression with different $\\alpha$ values, at least three.\n2. Implement a SGD method that will train the Lasso regression for 10 epochs.\n3. Extend the Fisher's classifier to work with two features. Use the class as the $y$.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Cross-validation linear regression\n\nYou need to change the variable ``alpha`` to be a list of alphas. Next do a loop and finally compare the results.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\n\nx = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\ny = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n\nx = np.asmatrix(np.c_[np.ones((15,1)),x])\n\nI = np.identity(2)\nalpha_list = [0.1, 0.3, 0.5, 0.7, 1] # change here\n\n# add 1-3 line of code here\nresults = []\nfor alpha in alpha_list:\n    w = np.linalg.inv(x.T*x + alpha * I)*x.T*y\n    w=w.ravel()\n    results.append(w)\n\n# add 1-3 lines to compare the results\nfor i, alpha in enumerate(alpha_list):\n    print('Alpha:', alpha, ', results:', results[i])\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Alpha: 0.1 , results: [[-101.72397081    1.16978757]]\nAlpha: 0.3 , results: [[-54.23704349   0.90096184]]\nAlpha: 0.5 , results: [[-36.97522016   0.80324169]]\nAlpha: 0.7 , results: [[-28.04797742   0.75270394]]\nAlpha: 1 , results: [[-20.59044706   0.71048616]]\n"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": "## 2. Implement based on the Ridge regression example, the Lasso regression.\n\nPlease implement the SGD method and compare the results with the sklearn Lasso regression results. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def sgd(features, target, alpha, max_iter=1000):\n    feat_mean, feat_std = np.mean(features), np.std(features)\n    target_mean, target_std = np.mean(target), np.std(target)\n    \n    norm_features = (features - feat_mean) / feat_std\n    norm_target = (target - target_mean) / target_std\n    \n    coefficient = np.random.normal(scale=0.1)\n    intercept = np.random.normal(scale=0.1)\n    \n    for iteration in range(max_iter):\n        random_indices = np.random.permutation(len(target))\n        \n        for i in random_indices:\n            x = norm_features[i]\n            y = norm_target[i]\n            prediction = coefficient * x + intercept\n            residual = prediction - y\n            coefficient -= alpha * residual * x\n            intercept -= alpha * residual\n    \n    coefficient = coefficient * (target_std / feat_std)\n    intercept = target_mean - coefficient * feat_mean\n    \n    return np.array([intercept, coefficient])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "import itertools\n\nx = np.array([188, 181, 197, 168, 167, 187, 178, 194, 140, 176, 168, 192, 173, 142, 176]).reshape(-1, 1).reshape(15,1)\ny = np.array([141, 106, 149, 59, 79, 136, 65, 136, 52, 87, 115, 140, 82, 69, 121]).reshape(-1, 1).reshape(15,1)\n\nI = np.identity(2)\nalpha = 0.001\n\nsgd_res = sgd(x, y, alpha)\nsgd_res = sgd_result.ravel()\n\nx = np.asmatrix(np.c_[np.ones((15,1)),x])\nw = np.linalg.inv(x.T*x + alpha * I)*x.T*y\nw = lasso_result.ravel()\n\nprint('sgd:', sgd_res[0], sgd_res[1])\nprint('lasso:', w.item(0), w.item(1))",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "sgd: -180.84289960253503 1.617679289698525\nlasso: -179.52628555248992 1.6102298475724885\n"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Extend the Fisher's classifier\n\nPlease extend the targets of the ``iris_data`` variable and use it as the $y$.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_iris\n\niris_data = load_iris()\niris_df = pd.DataFrame(iris_data.data,columns=iris_data.feature_names)\niris_df.head()\niris_df_target = iris_data.target\n\nx = iris_df[['sepal width (cm)', 'sepal length (cm)']].values # change here\ny = iris_df_target.reshape(-1, 1) # change here\n\ndataset_size = np.size(x)\n\nmean_x, mean_y = np.mean(x), np.mean(y)\n\nSS_xy = np.sum(y * x) - dataset_size * mean_y * mean_x\nSS_xx = np.sum(x * x) - dataset_size * mean_x * mean_x\n\na = SS_xy / SS_xx\nb = mean_y - a * mean_x\n\ny_pred = a * x + b\nprint(y_pred[:10], \"\\n...\\n\", y_pred[-10:])",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "[[0.92478522 1.05141831]\n [0.88521238 1.03558917]\n [0.90104152 1.01976004]\n [0.89312695 1.01184547]\n [0.93269979 1.04350374]\n [0.95644349 1.07516201]\n [0.91687065 1.01184547]\n [0.91687065 1.04350374]\n [0.87729781 0.99601633]\n [0.89312695 1.03558917]]\n...\n [[0.89312695 1.1780514 ]\n [0.89312695 1.19388053]\n [0.86146868 1.10682029]\n [0.90104152 1.18596596]\n [0.90895609 1.1780514 ]\n [0.88521238 1.1780514 ]\n [0.84563954 1.14639313]\n [0.88521238 1.16222226]\n [0.91687065 1.13847856]\n [0.88521238 1.11473485]]\n"
        }
      ],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}